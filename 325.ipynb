{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a376596-5e48-4277-be70-a615d66cde50",
   "metadata": {},
   "source": [
    "# Module 3: Intermediate Data Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2be2b6-1b40-48b1-a201-0206c926f0a3",
   "metadata": {},
   "source": [
    "## Sprint 2: Data Modeling with dbt & Analytics Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9b2f96-14f1-43de-b347-437cc8a2c7fa",
   "metadata": {},
   "source": [
    "## Part 5: Sales Data Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9aa1d0-6072-4552-b913-8fa3304dfe8d",
   "metadata": {},
   "source": [
    "## About this Part\n\nCongratulations! You've reached the final Part of this Sprint.\nThis Part serves as an integrative experience, allowing you to apply the knowledge and skills acquired in this and previous Sprints.\n\nAs the culmination of this Sprint, you'll set up a data modeling pipeline for a supermarket chain.\nSprint projects often necessitate using skills, tools, and techniques not explicitly covered during the Sprint.\nThis is intentional, as true expertise stems from the ability to recognize the skills needed to solve a given problem and to acquire these skills as necessary.\n\nRemember, perfection isn't expected at this stage.\nYou will continuously hone your skills and have ample opportunities to apply them in future projects.\nFor now, focus on leveraging what you've learned and giving it your best effort!\n\n## Context\n\nThe small boutique consulting firm specializing in data science and engineering that you founded with your friends had a really tough time finding clients in the FinTech sector.\nIt turns out that everybody has their proprietary creditworthiness models, and no one wants to share the data.\nYou have decided to pivot and target a more traditional type of business - specifically supermarkets.\nYou decided to make a demo application of a data warehouse, showcasing your data modeling and data engineering skills.\nYou decided to use [this Kaggle repository](https://www.kaggle.com/datasets/bhanupratapbiswas/superstore-sales) as your source data and transform it to a dimensional data model using dbt.\n\nNote: install dbt [using Docker](https://docs.getdbt.com/docs/core/docker-install). You are free to choose the database technology yourself.\n\n## Objectives for this Part\n\n- Practice using dimensional data modeling.\n- Practice using dbt.\n- Practice using Docker.\n\n## Requirements\n\n- Your solution should encompass the functionality outlined in the Context section.\n- Provide suggestions on how your analysis can be improved.\n\n## Evaluation Criteria\n\n- Adherence to the requirements. How well did you meet the requirements?\n- Code quality. Was your code well-structured? Did you use the appropriate levels of abstraction? Did you remove commented-out and unused code?\n- System design. Did your solution use suitable technologies, tools, software architecture, and algorithms?\n- Presentation quality. How comprehensive is your presentation, and how well are you able to explain your solution to the target audience?\n- Conceptual understanding. How well do you know the concepts covered in this and previous Sprints?\n\n## Correction\n\nDuring your project correction, you should present it as if talking to a potential client for whom you are showcasing your solution.  \nYou can assume that they will have some software and data engineering skills - they will understand technical jargon, but are not expected to notice and question things that could have been done better or ask about the choices you've made.\nThey are very familiar with the business domain and are looking for consultants that could help them with architecting and engineering.\n\nDuring the presentation, you might be asked questions to test your understanding of the covered topics, such as:\n\n- What is the primary objective of dimensional data modeling?\n- What is a star schema?\n- What is a snowflake schema?\n- How does the snowflake schema differ from a star schema? In what circumstances is it appropriate to use each of them?\n- In a star schema, how are dimension tables connected to the fact table?\n- What is a slowly changing dimension in dimensional data modeling?\n- What is the purpose of the bridge table in dimensional data modeling?\n\nIMPORTANT: during the correction, you will also be asked to solve an exercise using Python.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e87a87-b403-4ba9-836b-09926fadb79e",
   "metadata": {},
   "source": [
    "## General Correction Guidelines\n\nFor an in-depth explanation about how corrections work at Turing College, please read [this doc](https://turingcollege.atlassian.net/wiki/spaces/DLG/pages/537395951/Peer+expert+reviews+corrections).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
